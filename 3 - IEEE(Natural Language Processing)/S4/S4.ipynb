{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e0958f-aaa4-4f23-b482-b7c92de33db9",
   "metadata": {},
   "source": [
    "# Text Representation Techniques: BoW, TF-IDF, and n-grams\n",
    "\n",
    "## Agenda:\n",
    "1. **Introduction** - Overview of text representation methods.\n",
    "2. **Bag of Words (BoW)** - Explanation and implementation.\n",
    "3. **Term Frequency-Inverse Document Frequency (TF-IDF)** - Explanation and implementation.\n",
    "4. **n-grams** - Explanation and implementation.\n",
    "5. **Practical Applications** - Code for applying these methods on example data.\n",
    "6. **Summary** - Final thoughts and summary of techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd77780c-19bf-4b04-8d77-14f484b519a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will explore various techniques for representing text data numerically, including **Bag of Words (BoW)**, **TF-IDF**, and **n-grams**. These methods are commonly used in tasks like text classification, sentiment analysis, and other natural language processing (NLP) tasks.\n",
    "\n",
    "We will use simple examples to illustrate how each method works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8daa20-9421-4298-81d7-f1b5f7cb654d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bag of Words (BoW)\n",
    "\n",
    "**Bag of Words (BoW)** is a method for representing text data in a numerical format. It involves counting the frequency of each word in the document while ignoring grammar and word order.\n",
    "\n",
    "For example, let's consider the following sentences:\n",
    "\n",
    "1. **Sentence 1**: \"I have a food, I hate it tastes.\"\n",
    "2. **Sentence 2**: \"I have a pen.\"\n",
    "3. **Sentence 3**: \"The weather is beautiful.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70407f81-4b40-4a01-b34a-5f4d0ad8a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Representation:\n",
      " [[0 1 1 1 0 1 0 1 0 0]\n",
      " [0 0 0 1 0 0 1 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 1 1]]\n",
      "\n",
      "Feature Names (Words):\n",
      " ['beautiful' 'food' 'hate' 'have' 'is' 'it' 'pen' 'tastes' 'the' 'weather']\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Example sentences\n",
    "documents = [\n",
    "    \"I have a food, I hate it tastes.\",\n",
    "    \"I have a pen.\",\n",
    "    \"The weather is beautiful.\"\n",
    "]\n",
    "\n",
    "# Bag of Words (BoW)\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(documents)\n",
    "bow_array = bow_matrix.toarray()\n",
    "\n",
    "# Displaying the results\n",
    "print(\"BoW Representation:\\n\", bow_array)\n",
    "print(\"\\nFeature Names (Words):\\n\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890a4d4-1c06-4027-9718-59febf18644d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "**TF-IDF** is a more advanced method that adjusts the frequency of words based on how common or rare they are across all documents. It is calculated using two components:\n",
    "1. **Term Frequency (TF)**: The number of times a word appears in a document.\n",
    "2. **Inverse Document Frequency (IDF)**: A measure of how important a word is in the entire corpus.\n",
    "\n",
    "The formula for TF-IDF is:\n",
    "\n",
    "\\[\n",
    "\\text{TF-IDF}(t) = \\text{TF}(t) \\times \\log\\left(\\frac{N}{df(t)}\\right)\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( t \\) is the term,\n",
    "- \\( N \\) is the total number of documents,\n",
    "- \\( df(t) \\) is the number of documents containing the term \\( t \\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34ad21f-aa03-4bd0-a46b-0f6fa4492053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Representation:\n",
      " [[0.         0.46735098 0.46735098 0.35543247 0.         0.46735098\n",
      "  0.         0.46735098 0.         0.        ]\n",
      " [0.         0.         0.         0.60534851 0.         0.\n",
      "  0.79596054 0.         0.         0.        ]\n",
      " [0.5        0.         0.         0.         0.5        0.\n",
      "  0.         0.         0.5        0.5       ]]\n",
      "\n",
      "Feature Names (Words):\n",
      " ['beautiful' 'food' 'hate' 'have' 'is' 'it' 'pen' 'tastes' 'the' 'weather']\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# Displaying the results\n",
    "print(\"TF-IDF Representation:\\n\", tfidf_array)\n",
    "print(\"\\nFeature Names (Words):\\n\", tfidf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf2f39-1ad1-404e-b4be-b248c80fb59a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## n-grams\n",
    "\n",
    "**n-grams** are sequences of \\( n \\) words from a given text. They can be used to capture the context of the words in the text. The most common types are:\n",
    "1. **Unigrams**: Individual words.\n",
    "2. **Bigrams**: Pairs of consecutive words.\n",
    "3. **Trigrams**: Triplets of consecutive words.\n",
    "\n",
    "For example, using the sentence \"I have a food\":\n",
    "- **Unigrams**: [\"I\", \"have\", \"a\", \"food\"]\n",
    "- **Bigrams**: [\"I have\", \"have a\", \"a food\"]\n",
    "- **Trigrams**: [\"I have a\", \"have a food\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f89d10-58aa-4a24-aa53-d5873f86bc0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n-grams Representation (Unigrams, Bigrams, Trigrams):\n",
      " [[0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1]]\n",
      "\n",
      "Feature Names (n-grams):\n",
      " ['beautiful' 'food' 'food hate' 'food hate it' 'hate' 'hate it'\n",
      " 'hate it tastes' 'have' 'have food' 'have food hate' 'have pen' 'is'\n",
      " 'is beautiful' 'it' 'it tastes' 'pen' 'tastes' 'the' 'the weather'\n",
      " 'the weather is' 'weather' 'weather is' 'weather is beautiful']\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Example sentences\n",
    "documents = [\n",
    "    \"I have a food, I hate it tastes.\",\n",
    "    \"I have a pen.\",\n",
    "    \"The weather is beautiful.\"\n",
    "]\n",
    "\n",
    "# n-grams (Unigrams, Bigrams, Trigrams)\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3))  # Unigrams, Bigrams, and Trigrams\n",
    "ngram_matrix = vectorizer.fit_transform(documents)\n",
    "ngram_array = ngram_matrix.toarray()\n",
    "\n",
    "# Displaying the results\n",
    "print(\"n-grams Representation (Unigrams, Bigrams, Trigrams):\\n\", ngram_array)\n",
    "print(\"\\nFeature Names (n-grams):\\n\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e44bf5-73a6-46e7-84a6-11c4108c3e62",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we covered three common techniques for representing text numerically:\n",
    "1. **Bag of Words (BoW)**: Counts the frequency of each word in the text, but ignores word order.\n",
    "2. **TF-IDF**: Adjusts word frequencies based on their importance across documents, giving more weight to rare words.\n",
    "3. **n-grams**: Captures sequences of words, which helps in understanding the context and relationships between words.\n",
    "\n",
    "These techniques are foundational for many NLP tasks like text classification, sentiment analysis, and information retrieval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
