{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d51a30e9-49a7-4b77-8ea1-aa4762cba548",
    "_uuid": "f0a5b4f70663cbea46b2286cd286a3854260a850"
   },
   "source": [
    "# Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "21169e0d-9845-4e9f-84c6-9449e2887aea",
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "0ae4a4bf8b1261ddeeac36881aeead344b9f0fff"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "2a36d917-5ec2-4d4c-8d1a-2a53b642b527",
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "d3e8afaa523ccc4b18ad408027cd845f65b43ce3"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Video_Games_Sales_as_at_22_Dec_2016.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4b94925f-4028-4ad5-b87d-ff969b8a3e0d",
    "_uuid": "3fe1ac68135454a1e181e0b48a93ac2233b5e3e8"
   },
   "source": [
    "> preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>NES</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>Platform</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>29.08</td>\n",
       "      <td>3.58</td>\n",
       "      <td>6.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>40.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name Platform  Year_of_Release     Genre Publisher  NA_Sales  \\\n",
       "0         Wii Sports      Wii           2006.0    Sports  Nintendo     41.36   \n",
       "1  Super Mario Bros.      NES           1985.0  Platform  Nintendo     29.08   \n",
       "\n",
       "   EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  Critic_Count  \\\n",
       "0     28.96      3.77         8.45         82.53          76.0          51.0   \n",
       "1      3.58      6.81         0.77         40.24           NaN           NaN   \n",
       "\n",
       "  User_Score  User_Count Developer Rating  \n",
       "0          8       322.0  Nintendo      E  \n",
       "1        NaN         NaN       NaN    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16719 entries, 0 to 16718\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Name             16717 non-null  object \n",
      " 1   Platform         16719 non-null  object \n",
      " 2   Year_of_Release  16450 non-null  float64\n",
      " 3   Genre            16717 non-null  object \n",
      " 4   Publisher        16665 non-null  object \n",
      " 5   NA_Sales         16719 non-null  float64\n",
      " 6   EU_Sales         16719 non-null  float64\n",
      " 7   JP_Sales         16719 non-null  float64\n",
      " 8   Other_Sales      16719 non-null  float64\n",
      " 9   Global_Sales     16719 non-null  float64\n",
      " 10  Critic_Score     8137 non-null   float64\n",
      " 11  Critic_Count     8137 non-null   float64\n",
      " 12  User_Score       10015 non-null  object \n",
      " 13  User_Count       7590 non-null   float64\n",
      " 14  Developer        10096 non-null  object \n",
      " 15  Rating           9950 non-null   object \n",
      "dtypes: float64(9), object(7)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16719, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  2\n",
       "Platform              0\n",
       "Year_of_Release     269\n",
       "Genre                 2\n",
       "Publisher            54\n",
       "NA_Sales              0\n",
       "EU_Sales              0\n",
       "JP_Sales              0\n",
       "Other_Sales           0\n",
       "Global_Sales          0\n",
       "Critic_Score       8582\n",
       "Critic_Count       8582\n",
       "User_Score         6704\n",
       "User_Count         9129\n",
       "Developer          6623\n",
       "Rating             6769\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                  2\n",
       "Platform              0\n",
       "Year_of_Release     269\n",
       "Genre                 2\n",
       "Publisher            54\n",
       "NA_Sales              0\n",
       "EU_Sales              0\n",
       "JP_Sales              0\n",
       "Other_Sales           0\n",
       "Global_Sales          0\n",
       "Critic_Score       8582\n",
       "Critic_Count       8582\n",
       "User_Score         6704\n",
       "User_Count         9129\n",
       "Developer          6623\n",
       "Rating             6769\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As You See We Have Many Nulls And Empty Cells So We Handle It**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndata = data.dropna(inplace=True)\n",
    "Ndata = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6825, 16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ndata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>Sports</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>41.36</td>\n",
       "      <td>28.96</td>\n",
       "      <td>3.77</td>\n",
       "      <td>8.45</td>\n",
       "      <td>82.53</td>\n",
       "      <td>76.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8</td>\n",
       "      <td>322.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Racing</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>15.68</td>\n",
       "      <td>12.76</td>\n",
       "      <td>3.79</td>\n",
       "      <td>3.29</td>\n",
       "      <td>35.52</td>\n",
       "      <td>82.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>709.0</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name Platform  Year_of_Release   Genre Publisher  NA_Sales  \\\n",
       "0      Wii Sports      Wii           2006.0  Sports  Nintendo     41.36   \n",
       "1  Mario Kart Wii      Wii           2008.0  Racing  Nintendo     15.68   \n",
       "\n",
       "   EU_Sales  JP_Sales  Other_Sales  Global_Sales  Critic_Score  Critic_Count  \\\n",
       "0     28.96      3.77         8.45         82.53          76.0          51.0   \n",
       "1     12.76      3.79         3.29         35.52          82.0          73.0   \n",
       "\n",
       "  User_Score  User_Count Developer Rating  \n",
       "0          8       322.0  Nintendo      E  \n",
       "1        8.3       709.0  Nintendo      E  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ndata.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name               0\n",
       "Platform           0\n",
       "Year_of_Release    0\n",
       "Genre              0\n",
       "Publisher          0\n",
       "NA_Sales           0\n",
       "EU_Sales           0\n",
       "JP_Sales           0\n",
       "Other_Sales        0\n",
       "Global_Sales       0\n",
       "Critic_Score       0\n",
       "Critic_Count       0\n",
       "User_Score         0\n",
       "User_Count         0\n",
       "Developer          0\n",
       "Rating             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ndata.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name               0\n",
       "Platform           0\n",
       "Year_of_Release    0\n",
       "Genre              0\n",
       "Publisher          0\n",
       "NA_Sales           0\n",
       "EU_Sales           0\n",
       "JP_Sales           0\n",
       "Other_Sales        0\n",
       "Global_Sales       0\n",
       "Critic_Score       0\n",
       "Critic_Count       0\n",
       "User_Score         0\n",
       "User_Count         0\n",
       "Developer          0\n",
       "Rating             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ndata.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now Let's Detect Our Best Featuers That We Will Use For Forcasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd0b9bc1-6aaf-4dd5-bb81-3dfd84d440eb",
    "_uuid": "655521dfc57a3bcfa97a2bed213de5e6a8d1d2e6"
   },
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d79bfbc4-0d22-4559-90df-8155c5434bc8",
    "_uuid": "b5d32f0de467d92d1797112c39dbc84bc96de7d0"
   },
   "source": [
    "Let's look at what independent variables we will keep and whether there are N/A values etc.\n",
    "\n",
    "> Let's look at what features have N/A values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6b74c04a-a7bd-4180-a62f-4b6173e6ad95",
    "_uuid": "01529d7df3994e1eb25f355b080336c2c42166dc",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "missing_data.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "92b8ab71-400d-404d-86d2-e6dbcec9e277",
    "_uuid": "3ba2247e2cb18cde44f48ddea92cfa49912d0865"
   },
   "source": [
    "Here we have an issue. Critic_Score which may very well be the most important  independent variable, has almost 50 % of its values as N/A. Similarly roughly 40 % of data points are missing for User_Score which is highly likely one of the most important independent variables. This ratio of missing data is so large, that it cannot feasibly be filled with median values for instance.\n",
    "\n",
    "Lets try a workaround. As previously mentioned, it may be more relevant to look at only current or previous generation consoles. So let's find out what all the consoles in the dataset are. Then lets choose a subset of those and this will likely automatically reduce the missing ratio of the independent variables as lesser known consoles and console games might not have Metacritic scores. Two birds with one stone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e48e2003-d87b-417a-b486-ff62c41de799",
    "_uuid": "d5d6ed7a55e9d56ec3e467c0525f72bf8338a8d9",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(pd.value_counts(data[\"Platform\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d86c8b46-a878-455c-aeee-1768f05d43f5",
    "_uuid": "a88dcd58dff57139c21a0686c2991354c786466b"
   },
   "source": [
    "As we can see, there are actually a lot of different platforms in the dataset. As previously mentioned, it might be most relevant to look at only current gen consoles in our model, however the issue here is that we will have a limited amount of data. Therefore, let's widen our scope somewhat and look at the following platforms: PS3, PS4, X360, XOne, PC, Wii and WiiU. This ensures that we won't have too little data. Let's keep only relevant platforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "03555e81-f935-454e-aa44-97c5645f4f79",
    "_uuid": "58f6fb947bad2564db45bc830fb3f34af7f1eb5a",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = data[(data['Platform'] == 'PS3') | (data['Platform'] == 'PS4') | (data['Platform'] == 'X360') | (data['Platform'] == 'XOne') | (data['Platform'] == 'Wii') | (data['Platform'] == 'WiiU') | (data['Platform'] == 'PC')]\n",
    "\n",
    "#Let's double check the value counts to be sure\n",
    "print(pd.value_counts(data[\"Platform\"]))\n",
    "\n",
    "#Let's see the shape of the data again\n",
    "print(data.shape)\n",
    "\n",
    "#Lets see the missing ratios again\n",
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "missing_data.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c66f15d5-71bd-4012-84cf-58dc82a9f498",
    "_uuid": "64f06d5d5077d4f713f467d2dba9230d40d8afd0"
   },
   "source": [
    "So we still have almost 40 % of data points missing the critic score. This is still way too big, so let's drop all rows, that have N/A for Critic_Score. We cannot replace 40 % of the data with say, the median values. We must therefore eliminate N/A observations themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0798b8c6-9a28-4ce6-8b42-370d4bef3d9a",
    "_uuid": "83d08f70f4e7cfa7a911d83349fa198ff5a62b7d",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['Critic_Score'])\n",
    "\n",
    "#Let's see the shape of the data again\n",
    "print(data.shape)\n",
    "\n",
    "#Lets see the missing ratios again\n",
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "missing_data.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "34546a30-874d-49b2-9009-27465b296c09",
    "_uuid": "df8a6cefe6ba59e839953895528cd020a3ac689b"
   },
   "source": [
    "This looks better already. We've reached the point where we've dealt with N/A values for the most important variable and we still have enough data to work with. We still have to handle N/A values for the rest of the variables however, but this isn't as glaring of an issue as the missing ratios are relatively small, the highest being roughly 5 % for User_Count.\n",
    "\n",
    "Let's deal with the rest of the N/A values next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4a16501-6602-4cf5-93b2-a09e106a3635",
    "_uuid": "9588d4712bf0b78ae6f7e1c7ab0613356dd81bca"
   },
   "source": [
    "* For Publisher let's fill N/A's with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "54bf3444-8a70-4da0-b913-aa6bd7a85f47",
    "_uuid": "ab88ed3150bf56bb6d7a031859d1e9e2bf222e38",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data['Publisher'] = data['Publisher'].fillna(data['Publisher'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a8fea40a-ddaa-4796-9e1a-abd91a26890e",
    "_uuid": "9f226f516531a8af14cf88694334d48028a0037a"
   },
   "source": [
    "* For Developer let's fill N/A's with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9278afa3-14a7-45a5-a6dc-85a64e851201",
    "_uuid": "5a5397eff581ec9f6a99a1e05b17663f20904e02",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data['Developer'] = data['Developer'].fillna(data['Developer'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "425cb447-fc93-42c6-a5a7-a7750d73ba10",
    "_uuid": "f7cfc78b8766399b690401d0e8761a6bc7079e71"
   },
   "source": [
    "* For Rating let's fill N/A's with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "10d1bd32-142a-454b-bfdc-223258424717",
    "_uuid": "401bb1796d866babf3481829320267264c298908",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data['Rating'] = data['Rating'].fillna(data['Rating'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8211e1a1-490d-4805-89bf-f845ebb19874",
    "_uuid": "138b8a5a5294d3481397a35c9edb19e6e5b64b80"
   },
   "source": [
    "* For Year_of_Release let's fill with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3add8a81-da8a-4f48-af18-f68ebbabaf67",
    "_uuid": "183024d72e1c2181d0cda5a239b47ea6e29c7333",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data['Year_of_Release'] = data['Year_of_Release'].fillna(data['Year_of_Release'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "03c44d85-08d7-45ea-b476-e9ecab8d15b6",
    "_uuid": "5574957a656efd79c860c1235f4e9b57a23c046b"
   },
   "source": [
    "* For User_Score let's fill with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "884dbb63-d8ab-4fbd-9b0f-c9fc032b9224",
    "_uuid": "8768a60fc6cb8d329a879e8489fe72fbf677283a",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#There's \"tbd\" values in the mix here which we need to handle first\n",
    "data['User_Score'] = data['User_Score'].replace('tbd', None)\n",
    "\n",
    "#Now we can handle the N/A's appropriately\n",
    "data['User_Score'] = data['User_Score'].fillna(data['User_Score'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0a0925ac-6398-4420-8184-c57b7c50f4f6",
    "_uuid": "bff5649db4dbfbee30ae7ba888cb03a525dd148d"
   },
   "source": [
    "* For User_Count let's fill with the median value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b62a4ccd-8463-4ba1-a0dc-402d6196ab90",
    "_uuid": "4ffb99d6fe412c4657f1d50196edecadee5f7347",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data['User_Count'] = data['User_Count'].fillna(data['User_Count'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5fddf7e9-cc17-4352-9350-c1497cbaff89",
    "_uuid": "4a6f3f9b9935bc7eb5b02dab313048ccd8f7a7ad"
   },
   "source": [
    "* Now let's verify that we don't have any more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bb59b341-3434-463f-ae43-97ca474039b7",
    "_uuid": "e7ff79819d067428b9e0595e57fde66ad46a96ec",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Lets see the missing ratios again\n",
    "data_na = (data.isnull().sum() / len(data)) * 100\n",
    "data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n",
    "missing_data.head(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "db095564-485d-4f25-8ee2-8cc47f22621c",
    "_uuid": "352192035bc29d85ee3da65760e042fdbb969c7d"
   },
   "source": [
    "Hurray! We've dealt with all the missing values finally. Now let's deal with categorical values next. We need to change the following independent variables to dummy variables:\n",
    "\n",
    "* Platform\n",
    "* Genre\n",
    "* Publisher\n",
    "* Developer\n",
    "* Rating\n",
    "\n",
    "However, here we have an issue. Publisher and Developer will cause a massive influx of features as there are so many unique values in the mix. At this point it seems best to drop these features entirely.\n",
    "\n",
    "Instead, let's only create dummies for:\n",
    "\n",
    "* Platform\n",
    "* Genre\n",
    "* Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "40462ac3-b964-4618-959f-1cb61f706a7d",
    "_uuid": "2c797d08abbdf39dd062d8210e1207d112797107",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(data.shape) #pre-dummies shape\n",
    "data = pd.get_dummies(data=data, columns=['Platform', 'Genre', 'Rating'])\n",
    "print(data.shape) #post-dummies shape\n",
    "data.head #Check to verify that dummies are ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "046674bc-f6de-4351-bd2b-c4be166ff20c",
    "_uuid": "4c480475027fb09d6dd7539cdad913a859e882dc"
   },
   "source": [
    "Great! Let's drop the features we wish to discard for our models. These include:\n",
    "\n",
    "* Name\n",
    "* Publisher\n",
    "* Developer\n",
    "* NA_Sales\n",
    "* EU_Sales\n",
    "* JP_Sales\n",
    "* Other_Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "021f90b0-aa65-424a-aafe-897ca796023a",
    "_uuid": "4420562a69d3a8ecd11a09065236ccf4b7ddf249",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(['Name', 'Publisher', 'Developer', 'NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "20b3f4a7-b4b0-49e2-809d-c3408f956aae",
    "_uuid": "82283772c729b3aeb751068d4f4a1c7a5ad4c2e0"
   },
   "source": [
    " Let's define X and Y and then split into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f2045a0d-12e5-4123-9a62-08e763f15d82",
    "_uuid": "b43babbd90a6e48ca925ee827da5680a4a397393",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(data.columns) #easy to copy-paste the values to rearrange from here\n",
    "\n",
    "X = data[['Year_of_Release', 'Critic_Score', 'Critic_Count',\n",
    "       'User_Score', 'User_Count', 'Platform_PC', 'Platform_PS3',\n",
    "       'Platform_PS4', 'Platform_Wii', 'Platform_WiiU', 'Platform_X360',\n",
    "       'Platform_XOne', 'Genre_Action', 'Genre_Adventure', 'Genre_Fighting',\n",
    "       'Genre_Misc', 'Genre_Platform', 'Genre_Puzzle', 'Genre_Racing',\n",
    "       'Genre_Role-Playing', 'Genre_Shooter', 'Genre_Simulation',\n",
    "       'Genre_Sports', 'Genre_Strategy', 'Rating_E', 'Rating_E10+', 'Rating_M',\n",
    "       'Rating_RP', 'Rating_T']]\n",
    "\n",
    "Y = data[['Global_Sales']]\n",
    "\n",
    "#Double checking the shape\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "66632955-c50c-4337-9ad5-036b491c5bd0",
    "_uuid": "5a65f3acce86bbde6efbbde056148f3b74b199eb",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42)\n",
    "\n",
    "#Let's check the shape of the split data as a precaution\n",
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"Y_train shape: {}\".format(Y_train.shape))\n",
    "\n",
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"Y_test shape: {}\".format(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0b6d5b21-d60a-445b-b8b1-4b68788d1f79",
    "_uuid": "e2c91bb0e93bd08c49d8f266a9f80299e8224a70"
   },
   "source": [
    "Now that we have the test split into training and test data we can still do some final scaling of the data before fitting the models. \n",
    "\n",
    "As mentioned previously, lets do a log-transformation of the dependent variable in both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a5ca8ba8-4177-4bcc-9a94-d29e44154849",
    "_uuid": "ce20251262e98213f2d7db4365d9e4ffc1fa3d56",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\n",
    "Y_train = np.log1p(Y_train)\n",
    "Y_test = np.log1p(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bfd152a6-22ea-43a3-972f-df26e6a737c6",
    "_uuid": "05d53485a4c4c6993b62c41f4e99cb24a23000e6",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Check the new distribution \n",
    "Y_log_transformed = np.log1p(data['Global_Sales']) #For comparison to earlier, here's the whole Y transformed\n",
    "sns.distplot(Y_log_transformed , fit=norm);\n",
    "\n",
    "# Get the fitted parameters used by the function\n",
    "(mu, sigma) = norm.fit(Y_log_transformed)\n",
    "print( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "\n",
    "#Now plot the distribution\n",
    "plt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "            loc='best')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Global_Sales distribution')\n",
    "\n",
    "#Get also the QQ-plot\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(Y_log_transformed, plot=plt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4a22856b-c412-458a-a325-d60bdd0ff830",
    "_uuid": "13c4a4f3204d5f5fc94b3bc968c9cdb19a283a51"
   },
   "source": [
    "As we can see, the log-transformation didn't do too much to help us normalize the data. To be honest, this step might not be all that useful, especially if we choose to fit models that can handle non-linear data pretty well. None the less, not much harm done either, so let's proceed.\n",
    "\n",
    "Let's fit X_train and scale X_train and X_test with the MinMax Scaler to get all independent variables in a similar range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1dcfe97-7b2b-4890-a7ba-827dbc688660",
    "_uuid": "28e28010863413a76b1f8c3bd4d97a23f2518607",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e8989889-aaee-4971-aaeb-bd6cd580c8ba",
    "_uuid": "3ec66efc528381af872ffb0bdd231b65be0a9965"
   },
   "source": [
    "Now we are really close to the fun part. First however, we need to prepare our grids for grid search. For this, we need to decide, which models we will use. So let's try:\n",
    "\n",
    "* Linear Regression\n",
    "* Lasso\n",
    "* Ridge Regression\n",
    "* Support Vector Regressor\n",
    "* Random Forest\n",
    "* Gradient Boosting Regressor\n",
    "* MLP Regressor a.k.a. a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2fc2a2fb-763a-4c88-9e9f-10d9227379c3",
    "_uuid": "7df0801a72fb8a531732ed01698bc864f5b42795",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#No grid to define for vanilla linear regression\n",
    "param_grid_lr = [\n",
    "    {}\n",
    "]\n",
    "\n",
    "#Parameter grid for lasso\n",
    "param_grid_lasso = [\n",
    "    {'alpha': [10, 1, 0.1, 0.01, 0.001, 0.0001], 'max_iter': [1000000, 100000, 10000, 1000]}\n",
    "]\n",
    "\n",
    "#Parameter grid for Ridge Regression\n",
    "param_grid_rr = [\n",
    "    {'alpha': [100, 10, 1, 0.1, 0.01, 0.001]}\n",
    "]\n",
    "\n",
    "#Parameter grid for Support Vector Regressor\n",
    "param_grid_svr = [\n",
    "    {'C': [0.01, 0.1, 1, 10], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "     'kernel': ['rbf']}\n",
    "]\n",
    "\n",
    "#Parameter grid for Random Forest\n",
    "param_grid_rf = [\n",
    "    {'n_estimators': [3, 10, 30, 50, 70], 'max_features': [2,4,6,8,10,12], 'max_depth': [2, 3, 5, 7, 9]}\n",
    "]\n",
    "\n",
    "#Parameter grid for Gradient Boosting Regressor\n",
    "param_grid_gbr = [\n",
    "    {'n_estimators': [200, 225, 250, 275], 'max_features': [6, 8, 10, 12], 'max_depth': [5, 7, 9]}\n",
    "]\n",
    "\n",
    "#Parameter grid for MLPRegressor. \n",
    "#Current set of hyperparameters are the result of grid search that took forever.\n",
    "param_grid_mlpr = [\n",
    "    {'hidden_layer_sizes': [(10,5)], 'solver': ['lbfgs'], 'batch_size': [200],\n",
    "     'learning_rate': ['adaptive'], 'max_iter': [800], 'verbose': [True], \n",
    "     'nesterovs_momentum': [True], 'early_stopping': [True], 'validation_fraction': [0.12],\n",
    "     'random_state': [100], 'alpha': [0.1], 'activation': ['logistic']}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "21a0f64a-77cf-45f1-9e5b-f0e15ae2e821",
    "_uuid": "2dda4849e6e5243e332688ca76ddb4e9b5262eed"
   },
   "source": [
    "Now that we have the parameter grids, let's implement the models one by one and see which does the best. \n",
    "\n",
    "Let's use RMSE for scoring the models. The interpretation for RMSE, or Root Mean Squared Error, is more intuitive than that of the MSE as RMSE is an absolute measure of fit. It thus tells us our error in actual sales units. Also, to quote theanalysisfactor.com: \"RMSE is a good measure of how accurately the model predicts the response, and is the most important criterion for fit if the main purpose of the model is prediction.\"\n",
    "\n",
    "However, before interpreting the RMSE, we must also do an exp transformation on the RMSE scores to undo the log transformation and for the results to be more easily interpreted. Otherwise the RMSE will be in log(Global_Sales).\n",
    "\n",
    "In conjunction with our grid search, let's use cross-validation with 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c054c859-9f13-41a9-9609-51f016e279ed",
    "_uuid": "a789992a8eb83fb0e9ce45409f65cc095324fa2f",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search_lr = GridSearchCV(LinearRegression(), param_grid_lr, scoring='neg_mean_squared_error',  cv=5)\n",
    "grid_search_lr.fit(X_train, Y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_lr.best_params_))\n",
    "lr_best_cross_val_score = (np.sqrt(-grid_search_lr.best_score_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.expm1(lr_best_cross_val_score)))\n",
    "lr_score = np.sqrt(-grid_search_lr.score(X_test, Y_test))\n",
    "print(\"Test set score: {:.2f}\".format(np.expm1(lr_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da7a39f7-fb3e-4bd4-bdad-b0aaf57dd906",
    "_uuid": "e2edadf06c00549d6a7071933a5791e0a02ff87f",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "grid_search_lasso = GridSearchCV(Lasso(), param_grid_lasso, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_lasso.fit(X_train, Y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_lasso.best_params_))\n",
    "lasso_best_cross_val_score = (np.sqrt(-grid_search_lasso.best_score_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.expm1(lasso_best_cross_val_score)))\n",
    "lasso_score = np.sqrt(-grid_search_lasso.score(X_test, Y_test))\n",
    "print(\"Test set score: {:.2f}\".format(np.expm1(lasso_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7ab8127a-a3e7-4d27-87bb-2e71e14ae04f",
    "_uuid": "fbe09bfae48026c86c29eef4917682d7107d288b",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "grid_search_rr = GridSearchCV(Ridge(), param_grid_rr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_rr.fit(X_train, Y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_rr.best_params_))\n",
    "rr_best_cross_val_score = (np.sqrt(-grid_search_rr.best_score_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.expm1(rr_best_cross_val_score)))\n",
    "rr_score = np.sqrt(-grid_search_rr.score(X_test, Y_test))\n",
    "print(\"Test set score: {:.2f}\".format(np.expm1(rr_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1eba2c0d-536b-411d-8db4-7d6796fd7169",
    "_uuid": "7b47413582d4a8917bbe985905dbce5c328221a8",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "grid_search_svr = GridSearchCV(SVR(), param_grid_svr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_svr.fit(X_train, Y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_svr.best_params_))\n",
    "svr_best_cross_val_score = (np.sqrt(-grid_search_svr.best_score_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.expm1(svr_best_cross_val_score)))\n",
    "svr_score = np.sqrt(-grid_search_svr.score(X_test, Y_test))\n",
    "print(\"Test set score: {:.2f}\".format(np.expm1(svr_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "177d6fd8-63bb-4df9-a296-aa5ef41300fa",
    "_uuid": "ea622975d04f413c9cb838bad25091d86b3d2577",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(), param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_rf.fit(X_train, Y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_rf.best_params_))\n",
    "rf_best_cross_val_score = (np.sqrt(-grid_search_rf.best_score_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.expm1(rf_best_cross_val_score)))\n",
    "rf_score = np.sqrt(-grid_search_rf.score(X_test, Y_test))\n",
    "print(\"Test set score: {:.2f}\".format(np.expm1(rf_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e44aa789-01eb-4ec1-995c-1aad71140732",
    "_uuid": "ed08dfc2b0972f0f62a4903a9737ea81ecdb08c7",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "grid_search_gbr = GridSearchCV(GradientBoostingRegressor(), param_grid_gbr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_gbr.fit(X_train, Y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_gbr.best_params_))\n",
    "gbr_best_cross_val_score = (np.sqrt(-grid_search_gbr.best_score_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.expm1(gbr_best_cross_val_score)))\n",
    "gbr_score = np.sqrt(-grid_search_gbr.score(X_test, Y_test))\n",
    "print(\"Test set score: {:.2f}\".format(np.expm1(gbr_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8da32ce2-0538-4a92-8324-76f306b7bdc0",
    "_uuid": "8c740a22f4d1ef37634e91cdf4b5ca262f94d848",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "grid_search_mlpr = GridSearchCV(MLPRegressor(), param_grid_mlpr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_mlpr.fit(X_train, Y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search_mlpr.best_params_))\n",
    "mlpr_best_cross_val_score = (np.sqrt(-grid_search_mlpr.best_score_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(np.expm1(mlpr_best_cross_val_score)))\n",
    "mlpr_score = np.sqrt(-grid_search_mlpr.score(X_test, Y_test))\n",
    "print(\"Test set score: {:.2f}\".format(np.expm1(mlpr_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bcd60ed3-2aea-4d25-90ce-626b8a94de54",
    "_uuid": "1848dd070b95cd0febd87aa5d4e51aaddd6e620e"
   },
   "source": [
    "So the best model out of the seven we trained is the GBR! Let's therefore take a loot at the feature importances of the model as well to find out which features are the most important ones in explaining the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bde3359f-47f6-4bef-bed7-f827bd3d5341",
    "_uuid": "6d0225f079abb7407d68edc72f10412d805c5bfa",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "feature_importance = grid_search_gbr.best_estimator_.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X_train.columns.values[sorted_idx]) #Not 100 % sure the feature names match the importances correctly...\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4a745698-4236-4aa7-8be7-932c01490576",
    "_uuid": "c03267600e168d72fbb75a44084121569e4455bd"
   },
   "source": [
    "**Results**\n",
    "\n",
    "Surprisingly, the best model IS NOT the deep neural network. Instead it's the Gradient Boosting Regressor. I would have initially picked it out to be the second best one out of the lot. This speaks to it's power as a model and also to the fact that training deep neural networks is challenging and a lot of the time it seems that you're better off choosing a simpler model, as the computational expense that DNN's bring with them may not justify the decrease in MSRE. In a sense it's kind of a \"don't bring a gun to a fistfight\" type of situation, if that makes any sense... \n",
    "\n",
    "As this was my first time training a neural network, it really dawned on me how difficult tuning those hyperparameters is to optimize your model. At the same time I can more clearly see the value in using a library like Tensorflow for training DNN's as the library brings more flexibility that can prove to be invaluable. \n",
    "\n",
    "Anyway, on to the analysis of the results! So the GBR's best cross-validation score and its test score are both 0.33 as measured in RMSE. This means that first off, the model generalizes well as the difference between the cross-validation score and the test set score is negligible. In more concrete terms however, it means that the average error the model makes in its predicitons amount to 330k units. That means that in making a forecast, on average the model will be wrong in forecasting video game sales by 330k units.\n",
    "\n",
    "Additionally, an interesting finding is that the amount of users and the amount of critics rating a game on Metacritic is more important in explaining the results than the scores themselves. My initial hypothesis would have been the other way around. In this regard, it seems that it doesn't necessarily matter as much that a game has a single esteemed critic scoring the game a 100, but rather that the game has lots of critics scoring it potentially even at a lower level to drive those unit sales.\n",
    "\n",
    "Another interesting finding is that the year of release is the fifth most important factor in explaingin the results. I would wager here that this is an indication of the fast growing video game industry: as the value for the year increases, unit sales increases mainly due to the market itself growing.\n",
    "\n",
    "In terms of platforms, the only ones that maintained some relevant measure of explanatory power was whether the game was released on PC and whether it was released on Wii. There may be many interpretations here, so it is best to be wary in interpreting this. A game being released on Wii might speak towards explaining lower unit sales due to the platform not being as popular as it's counter parts PS3 and Xbox 360. In the case of a game being released on PC, it is difficult to say which way this explanatory power goes, as PC is such a large platform with all kinds of games being released on it.\n",
    "\n",
    "However, let's get to the real question: is the model good or not?\n",
    "\n",
    "Well, it depends on the point of view. If you would use this model to forecast the unit sales of a small video game developer's game, you would be better of using other methods. The reason is that typically independent smaller studios sell under a million copies. In this case, an error of 330k units is a lot and can have a tremendous financial impact on the company, if you are relying on forecasting sales with this model. However, if you use this model to forecast the unit sales of larger AAA game developer's game, an error of 330k units, isn't that fatal. If you're forecasting the unit sales of a developer who typically sells say 3 million copies, then a roughly 10 % deviation is not fatal. Sure it isn't close to perfect, but these type of models typically aren't.\n",
    "\n",
    "So where might this model come in valuable then? I think the most obvious example is in business teams in large video game companies. They typically make sales estimates that are then reflected in project budgets etc. and most of the time, the estimates are made in similar ways that for example equity analysts make forecasts: coming up with a number off of the top of your head :) This model could thus be used as an extra input in making those sales forecasts. \n",
    "\n",
    "To finish off: creating this kernel was a lot of fun! I appreciate all types of feedback as I'm only a beginner in both Python and Machine Learning! Thanks to anyone who took the time to read this and I hope you enjoyed it!\n",
    "\n",
    "\n",
    "-jruots\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
